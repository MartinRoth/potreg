---
title: "Nonstationary Regional Frequency Analysis with Peaks-Over-Threshold Data"
author: "Martin Roth"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, fig.show='hold', include=FALSE}
library(data.table)
library(ggplot2)
library(foreach)
library(iterators)
library(potreg)
library(doParallel)
registerDoParallel(1)
```

```{r, fig.show='hold'}
admNL <- raster::getData('GADM', country='NL', path="../inst/extdata", level=0)
fadmNL <- fortify(admNL)
if(!file.exists("../inst/extdata/NL_eobs_rr_0.50.rds")) {
  data  <- eobsR::importEOBS('rr', '1950/2015', admNL, "0.50reg")
  saveRDS(data, file = "../inst/extdata/NL_eobs_rr_0.50.rds")
} else {
  data <- readRDS("../inst/extdata/NL_eobs_rr_0.50.rds")
}
data <- SubsetSeasons(data, "winter")

knitr::kable(head(data))
```

```{r, fig.show='hold', fig.cap="Mean winter maxima per grid box."}
ggplot(fadmNL, aes(x = long, y = lat, group = group)) +
  geom_path() + coord_map() + 
  geom_tile(aes(x = lon, y = lat, fill = mRR, group = NULL), data = 
              data[, .(RR = max(rr)),
                   by = .(season, lat, lon)][, .(mRR = mean(RR)),
                                           by = .(lat, lon)],
            alpha = 0.5) + 
  scale_fill_distiller(palette = "Spectral", guide =guide_legend(reverse=TRUE))
```

### Decluster the data
```{r, fig.show='hold'}
if(!file.exists("../inst/extdata/NL_eobs_rrSep_0.50.rds")) {
  julianDays <- as.numeric(data[pointID == 1, julian(time, origin=as.Date("1950-01-01"))])
  declusterData <- function(x) {
    index <- evanHelpers::declusterSimpleSeparation(julianDays, x, sep=1)
    x[-index] <- 0
    return(x)
  }
  data[, rrSep := declusterData(rr), by = pointID]
  saveRDS(data, file = "../inst/extdata/NL_eobs_rrSep_0.50.rds")
} else {
  data <- readRDS("../inst/extdata/NL_eobs_rrSep_0.50.rds")
}
knitr::kable(head(data))
```

### Compute the threshold
```{r, fig.show='hold'}
if(!file.exists("../inst/extdata/NL_eobs_threshold_0.50.rds")) {
  data[, threshold := -1]
  data[, pVal := -1]
  setkey(data, pointID)
  foreach(x=unique(data[["pointID"]]), .inorder=FALSE) %do% {
    fit <- data[.(x), quantreg::rq(rrSep ~ season, tau = 0.96)]
    data[.(x), threshold := fit$fitted.values]
    data[.(x), pVal := summary(fit)$coefficients[2, 4]]
  }
  saveRDS(data, file = "../inst/extdata/NL_eobs_threshold_0.50.rds")
} else {
  data <- readRDS("../inst/extdata/NL_eobs_threshold_0.50.rds")
}
knitr::kable(head(data))
```

```{r, fig.show='hold', fig.cap="Threshold statistics."}
ggplot(fadmNL, aes(x = long, y = lat, group = group)) +
  geom_path() + coord_map() + 
  geom_tile(aes(x = lon, y = lat, fill = mean, group = NULL), data = 
              data[, .(mean = mean(threshold)), by = .(lat, lon)],
            alpha = 0.5) + 
  scale_fill_distiller(palette = "Spectral", guide =guide_legend(reverse=TRUE))
ggplot(fadmNL, aes(x = long, y = lat, group = group)) +
  geom_path() + coord_map() + 
  geom_tile(aes(x = lon, y = lat, fill = trend, group = NULL),
            data = data[, .(trend = diff(range(threshold))*10/max(season)),
                        by = .(lat, lon)],
            alpha = 0.5) + 
  geom_point(aes(x=lon, y = lat, group=NULL),
             shape = 1,
             data = data[, unique(pVal), by = .(lat, lon)][V1 < 0.05, ]) +
  scale_fill_distiller(palette = "Spectral", guide =guide_legend(reverse=TRUE))
```

### Set excesses

```{r, fig.show='hold'}
data[, pVal := NULL]
data[, excess := rrSep - threshold]
data[excess <= 0, excess := NA]
knitr::kable(head(data))
```

We expect `r data[, max(season)] * (1 - 0.96) * 90.25` exceedances per grid box. The actual sample size varies between `r min(data[!is.na(excess), .N, by = pointID][, N])` and `r max(data[!is.na(excess), .N, by = pointID][, N])` exceedances per grid box. In total we observe `r data[, any(!is.na(excess)), by = time][, length(which(V1))]` days with at least one exceedance.

```{r, fig.show='hold'}
poissonData <- data[pointID == 1, .(N = length(which(!is.na(excess))), year = min(year)), by = season]
poissonData[, countExcesses := cumsum(N)]
poissonData[, fitted := (sum(N) / .N) * (1 : .N) ]
poissonData[, lower := qCondPoisProcess(0.025, 1 : .N, .N, sum(N))]
poissonData[, upper := qCondPoisProcess(0.975, 1 : .N, .N, sum(N))]
ggplot(poissonData, aes(x = year, y = countExcesses)) + geom_line() + 
  geom_smooth(aes(y = fitted, ymin = lower, ymax = upper), stat = "identity") +
  ylab("Cumulative number of excesses") + xlab("")
```

### Switch to old/matrix format of the data
```{r, fig.show='hold'}
setkey(data, pointID, time)
xpar <- list()
xpar$S <- data[, length(unique(pointID))]
xpar$T <- data[pointID == 1, .N]
xpar$julian <- data[pointID == 1, as.numeric(julian(time, origin=as.Date("1950-01-01")))]
xpar$threshold <- data[, threshold]
dim(xpar$threshold) <- c(xpar$T, xpar$S)

datMat <- data[, excess]
dim(datMat) <- c(xpar$T, xpar$S)
stopifnot(all(datMat[, 5] == data[pointID==5, excess], na.rm=TRUE))
```

```{r, fig.show='hold'}
modelA <- function(p, xpar) {
    scale <- p[1] * xpar$threshold
    shape <- matrix(p[2], xpar$T, xpar$S)
    list(scale = scale, shape = shape)
}

startA <- c(0.5, 0.0)

A <- fitGpdFlex(data = datMat, xpar = xpar, fpar = modelA, hessian = TRUE,
                numberOfParameters = 2, start = startA,  method = "BFGS",
                control = list(maxit = 5000, ndeps = c(1e-03, 1e-05)))
```

```{r, fig.show='hold'}
modelAprime <- function(p, xpar) {
    scale <- (p[1] + p[2] * (xpar$julian- mean(xpar$julian))) * xpar$threshold
    shape <- matrix(p[3], xpar$T, xpar$S)
    list(scale = scale, shape = shape)
}

startAprime <- c(0.5, 0, 0.05)

Aprime <- fitGpdFlex(data = datMat, xpar = xpar, fpar = modelAprime, hessian = TRUE,
                     numberOfParameters = 3, start = startAprime,
                     method = "BFGS", control = list(maxit = 5000, ndeps = c(1e-03, 1e-7, 1e-05)))
```

```{r, fig.show='hold'}
modelA2prime <- function(p, xpar) {
    scale <- p[1] * xpar$threshold  
    shape <- matrix(p[2] + p[3] * (xpar$julian - mean(xpar$julian)), xpar$T, xpar$S)
    list(scale = scale, shape = shape)
}

startA2prime <- c(0.5, 0, 0)

A2prime <- fitGpdFlex(data = datMat, xpar = xpar, fpar = modelA2prime, hessian = TRUE
                      numberOfParameters = 3, start = startA2prime, method = "BFGS",
                      control = list(maxit = 10000, ndeps = c(1e-03, 1e-4, 1e-6)))
```

```{r, fig.show='hold'}
if(!file.exists("../inst/extdata/shapeEvolution20.rds")) {
  shapeEvolution20 <- foreach(i = 1950 : 1995, .combine = "c") %dopar% { #1989
    dataSmall <- data[year %in% (i:(i+20)), ]
    xparSmall <- list()
    xparSmall$S <- dataSmall[, length(unique(pointID))]
    xparSmall$T <- dataSmall[pointID == 1, .N]
    xparSmall$julian <- dataSmall[pointID == 1, as.numeric(julian(time, origin=as.Date("1950-01-01")))]
    xparSmall$threshold <- dataSmall[, threshold]
    dim(xparSmall$threshold) <- c(xparSmall$T, xparSmall$S)
  
    datMatSmall <- dataSmall[, excess]
    dim(datMatSmall) <- c(xparSmall$T, xparSmall$S)
    
    fit <- fitGpdFlex(data = datMatSmall, xpar = xparSmall, fpar = modelA,
                  numberOfParameters = 2, start = startA,  method = "BFGS",
                  control = list(maxit = 5000, ndeps = c(1e-03, 1e-05)))
   
    return(fit$shape[1])
  }
  saveRDS(shapeEvolution20, file = "../inst/extdata/shapeEvolution20.rds")
} else {
  shapeEvolution20 <- readRDS("../inst/extdata/shapeEvolution20.rds")
}
```

```{r, fig.show='hold'}
plotData <- data[pointID == 1, .(time, year) ]
plotData[, A := A$shape[, 1]]
plotData[, A2prime := A2prime$shape[, 1]]
plotData <- plotData[, .(A = mean(A), A2prime = mean(A2prime)), by = year]
plotData[, evolution20 := NA_real_]
plotData[year %in% 1960 : 2005, evolution20 := shapeEvolution20]

ggplot(plotData, aes(x = year, y = evolution20)) +
  geom_point(col = 2) + geom_line(col = 2) +
  geom_line(aes(y = A2prime), lty=2) +
  geom_line(aes(y = A), lty = 3)

```

```{r, fig.show='hold'}
# days with at least one event
commonIndex <- data[, any(!is.na(excess)), by = time][, length(which(V1))]

sensitivityMatrix <- function(data, xpar, estimate, score, progress = TRUE) {
    result <- foreach(i = 1 : xpar$T) %do% {
        local <- foreach(j = 1 : xpar$S) %do% {
             scoreValue <- score(data, xpar, estimate, i, j)
             return(t(scoreValue) %*% scoreValue)
        }
        local <- Reduce("+", local)
        if(progress) progress(xpar$T, i)
        return(local)
    }
    result <- Reduce("+", result)
    return(result)
} 

variabilityMatrix <- function(data, xpar, estimate, score, progress = TRUE) {
    result <- foreach(i = 1 : dim(data)[1]) %dopar% {
        scoreValue <- score(data, xpar, estimate, i)
        if(progress) progress(xpar$T, i)
        return(t(scoreValue) %*% scoreValue)
    }
    tmp <- Reduce("+", result)
    return(tmp)
}

scoreA <- function(data, xpar, estimate, time, space = "all") {
    y <- data[time, ]
    u <- xpar$threshold[time, ]

    if (space != "all") {
        y <- data[time, space]
        u <- xpar$threshold[time, space]
    }

    if (all(is.na(y))) gradient <- matrix(c(0, 0), nrow = 1, ncol = 2)
    else {
        gamma <- estimate[1]
        xi    <- estimate[2]

        a <- gamma * u
        b <- xi * y
        c <- a + b
        d <- xi * y / (u * gamma) + 1

        dGamma <- - sum( 1 / gamma - (xi + 1) * y / (u * d * gamma^2), na.rm = TRUE)
        dXi    <- - sum( (xi + 1) * y / (u * xi * d * gamma) - (xi + 1) * log(d) / xi^2 + log(d) / xi, na.rm = TRUE)

        gradient <- matrix(c(dGamma, dXi), nrow = 1, ncol = 2)
    }
    colnames(gradient) <- c("gamma", "xi")
    return(gradient)
}

progress <- function (n, i) {
    step <- max(c(10, floor(n / 33)))
    if (n >= 10) {
        if (i%%step == 0) {
            percentage <- round(i/n * 100, 1)
            print(paste(percentage, "% done", sep = ""))
        }
    }
}

JA       <- variabilityMatrix(datMat, xpar, A$estimate, scoreA)
HA       <- sensitivityMatrix(datMat, xpar, A$estimate, scoreA)
GA       <- HA %*% solve(JA) %*% HA
penaltyA <- sum(diag(HA %*% solve(GA)))
TICA     <- A$deviance + 2 * penaltyA
BICA     <- A$deviance + log(commonIndex) * penaltyA
```

- reproduce figures 7, 8, 9, 10, 11
- reproduce table 1 and 2

Most computations are to be found in "Dropbox/Work/Rwork/Scriptfiles/0_computation.R"
The corrections made after the review of the second paper are to be found in  "Dropbox/Work/Rwork/Scriptfiles/01_reviews.R"
Go also carfully over the functions in "Dropbox/Work/Rwork/Scriptfiles/0_all_functions.R"



Vignettes are long form documentation commonly included in packages. Because they are part of the distribution of the package, they need to be as compact as possible. The `html_vignette` output type provides a custom style sheet (and tweaks some options) to ensure that the resulting html is as small as possible. The `html_vignette` format:

- Never uses retina figures
- Has a smaller default figure size
- Uses a custom CSS stylesheet instead of the default Twitter Bootstrap style

## Vignette Info

Note the various macros within the `vignette` section of the metadata block above. These are required in order to instruct R how to build the vignette. Note that you should change the `title` field and the `\VignetteIndexEntry` to match the title of your vignette.

## Styles

The `html_vignette` template includes a basic CSS theme. To override this theme you can specify your own CSS in the document metadata as follows:

    output: 
      rmarkdown::html_vignette:
        css: mystyles.css

## Figures

The figure sizes have been customised so that you can easily put two images side-by-side. 

```{r, fig.show='hold'}
plot(1:10)
plot(10:1)
```

You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
